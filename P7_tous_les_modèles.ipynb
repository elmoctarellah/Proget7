{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('C:/Users/bigdata/Projet7/application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('C:/Users/bigdata/Projet7/application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('C:/Users/bigdata/Projet7/bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('C:/Users/bigdata/Projet7/bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return bureau_agg\n",
    "\n",
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('C:/Users/bigdata/Projet7/previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return prev_agg\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('C:/Users/bigdata/Projet7/POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return pos_agg\n",
    "    \n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('C:/Users/bigdata/Projet7/installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return ins_agg\n",
    "\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('C:/Users/bigdata/Projet7/credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(debug = False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Bureau df shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 46s\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 59s\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 27s\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 123s\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 63s\n"
     ]
    }
   ],
   "source": [
    "data = main(debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "      <th>CC_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AMT_ANNUITY  AMT_CREDIT  AMT_GOODS_PRICE  AMT_INCOME_TOTAL  \\\n",
       "0      0      24700.5    406597.5         351000.0          202500.0   \n",
       "1      1      35698.5   1293502.5        1129500.0          270000.0   \n",
       "2      2       6750.0    135000.0         135000.0           67500.0   \n",
       "3      3      29686.5    312682.5         297000.0          135000.0   \n",
       "4      4      21865.5    513000.0         513000.0          121500.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        NaN                         NaN   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        NaN                        NaN   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  ...  CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "0                         0.0  ...                                 NaN   \n",
       "1                         0.0  ...                                 NaN   \n",
       "2                         0.0  ...                                 NaN   \n",
       "3                         NaN  ...                                 0.0   \n",
       "4                         0.0  ...                                 NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_Signed_MEAN  CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "0                                  NaN                                 NaN   \n",
       "1                                  NaN                                 NaN   \n",
       "2                                  NaN                                 NaN   \n",
       "3                                  0.0                                 0.0   \n",
       "4                                  NaN                                 NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  \\\n",
       "0                                 NaN                              NaN   \n",
       "1                                 NaN                              NaN   \n",
       "2                                 NaN                              NaN   \n",
       "3                                 0.0                              0.0   \n",
       "4                                 NaN                              NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  \\\n",
       "0                              NaN                               NaN   \n",
       "1                              NaN                               NaN   \n",
       "2                              NaN                               NaN   \n",
       "3                              0.0                               0.0   \n",
       "4                              NaN                               NaN   \n",
       "\n",
       "   CC_NAME_CONTRACT_STATUS_nan_SUM  CC_NAME_CONTRACT_STATUS_nan_VAR  CC_COUNT  \n",
       "0                              NaN                              NaN       NaN  \n",
       "1                              NaN                              NaN       NaN  \n",
       "2                              NaN                              NaN       NaN  \n",
       "3                              0.0                              0.0       6.0  \n",
       "4                              NaN                              NaN       NaN  \n",
       "\n",
       "[5 rows x 798 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356251, 798)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data['TARGET'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 798)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les valeurs manquantes par le médian de chaque colonne\n",
    "#df1 = df.apply(lambda x: x.fillna(x.mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les valeurs manquantes par le médian de chaque colonne\n",
    "df2 = df1.apply(lambda x: x.fillna(x.median()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier test sur 1% des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df2.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075, 798)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset.drop(['TARGET','SK_ID_CURR','index'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y, test_size=0.3, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardiser les données\n",
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.50 time 0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "\n",
    "dclf = DummyClassifier(strategy = 'most_frequent', random_state =42) \n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "dclf.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed0 = timeit.default_timer() - start_time\n",
    "\n",
    "y_pred_dum = dclf.predict(X_test_std)\n",
    "\n",
    "y_prob_dum = dclf.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, y_prob_dum)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.69 time 8.07s\n"
     ]
    }
   ],
   "source": [
    "# Créer une SVM avec un noyau gaussien de paramètre gamma=0.01\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='rbf', gamma=0.01, random_state =42)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Entraîner la SVM sur le jeu d'entraînement\n",
    "classifier.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "# prédire sur le jeu de test\n",
    "y_test_pred = classifier.decision_function(X_test_std)\n",
    "\n",
    "y_proba = (1/(1 + np.exp(-y_test_pred)))\n",
    "\n",
    "\n",
    "\n",
    "roc_value = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.71 time 635.99s\n",
      "The optimal parameters are {'C': 10.0, 'gamma': 0.01} with a score of 0.61\n",
      "{'mean_fit_time': array([5.41292744, 5.33147578, 5.69088163, 5.9244565 , 5.57316828,\n",
      "       6.16864548, 5.35368948, 5.45883307, 4.45637941, 3.41268525,\n",
      "       3.41311407, 3.41924715, 3.34307775, 3.35224657, 3.48928633,\n",
      "       3.52639351, 3.3795742 , 3.35413256, 3.53813868, 3.52468162,\n",
      "       3.37452793, 3.36860905, 3.68375268, 3.5820384 ]), 'std_fit_time': array([0.10569442, 0.28215872, 0.25673387, 0.14952579, 0.4031113 ,\n",
      "       0.92797125, 0.4705368 , 0.29251867, 0.58027342, 0.1636388 ,\n",
      "       0.05904785, 0.06370609, 0.0620976 , 0.06758132, 0.07193603,\n",
      "       0.06550336, 0.10149264, 0.07408017, 0.07443473, 0.07571862,\n",
      "       0.06497649, 0.07135239, 0.20638264, 0.11497936]), 'mean_score_time': array([1.23530526, 1.37183771, 1.54181986, 1.48023095, 1.48086524,\n",
      "       1.3524003 , 1.40600023, 1.38777232, 1.01912808, 0.85760183,\n",
      "       0.85059705, 0.87325559, 0.82199206, 0.80225906, 0.85929837,\n",
      "       0.88125958, 0.80305467, 0.83836498, 0.84794188, 0.84972653,\n",
      "       0.82858276, 0.80324812, 0.87657843, 0.85789843]), 'std_score_time': array([0.20222819, 0.17749521, 0.13131556, 0.07269488, 0.04559391,\n",
      "       0.18732117, 0.04981105, 0.10373932, 0.04186694, 0.05030223,\n",
      "       0.03110926, 0.06218496, 0.05283237, 0.01071465, 0.02705082,\n",
      "       0.08247938, 0.01802575, 0.04708747, 0.01237441, 0.020411  ,\n",
      "       0.04064485, 0.00631293, 0.04394623, 0.01663857]), 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 1.0, 1.0,\n",
      "                   1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 100.0, 100.0, 100.0,\n",
      "                   100.0, 1000.0, 1000.0, 1000.0, 1000.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.01, 0.1, 1.0, 10.0, 0.01, 0.1, 1.0, 10.0, 0.01, 0.1,\n",
      "                   1.0, 10.0, 0.01, 0.1, 1.0, 10.0, 0.01, 0.1, 1.0, 10.0,\n",
      "                   0.01, 0.1, 1.0, 10.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01, 'gamma': 0.01}, {'C': 0.01, 'gamma': 0.1}, {'C': 0.01, 'gamma': 1.0}, {'C': 0.01, 'gamma': 10.0}, {'C': 0.1, 'gamma': 0.01}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 1.0}, {'C': 0.1, 'gamma': 10.0}, {'C': 1.0, 'gamma': 0.01}, {'C': 1.0, 'gamma': 0.1}, {'C': 1.0, 'gamma': 1.0}, {'C': 1.0, 'gamma': 10.0}, {'C': 10.0, 'gamma': 0.01}, {'C': 10.0, 'gamma': 0.1}, {'C': 10.0, 'gamma': 1.0}, {'C': 10.0, 'gamma': 10.0}, {'C': 100.0, 'gamma': 0.01}, {'C': 100.0, 'gamma': 0.1}, {'C': 100.0, 'gamma': 1.0}, {'C': 100.0, 'gamma': 10.0}, {'C': 1000.0, 'gamma': 0.01}, {'C': 1000.0, 'gamma': 0.1}, {'C': 1000.0, 'gamma': 1.0}, {'C': 1000.0, 'gamma': 10.0}], 'split0_test_score': array([0.56281407, 0.46904979, 0.5       , 0.5       , 0.57065631,\n",
      "       0.5030836 , 0.5       , 0.5       , 0.57126542, 0.46958276,\n",
      "       0.5       , 0.5       , 0.56913355, 0.46410081, 0.5       ,\n",
      "       0.5       , 0.56913355, 0.46410081, 0.5       , 0.5       ,\n",
      "       0.56913355, 0.46410081, 0.5       , 0.5       ]), 'split1_test_score': array([0.65969032, 0.50933472, 0.5       , 0.5       , 0.6667284 ,\n",
      "       0.53381983, 0.5       , 0.5       , 0.66469107, 0.54967403,\n",
      "       0.5       , 0.5       , 0.66017188, 0.5498222 , 0.5       ,\n",
      "       0.5       , 0.66017188, 0.5498222 , 0.5       , 0.5       ,\n",
      "       0.66017188, 0.5498222 , 0.5       , 0.5       ]), 'split2_test_score': array([0.58781772, 0.4907259 , 0.5       , 0.5       , 0.59422945,\n",
      "       0.47736814, 0.5       , 0.5       , 0.59484009, 0.48706206,\n",
      "       0.5       , 0.5       , 0.59590871, 0.49026792, 0.5       ,\n",
      "       0.5       , 0.59590871, 0.49026792, 0.5       , 0.5       ,\n",
      "       0.59590871, 0.49026792, 0.5       , 0.5       ]), 'split3_test_score': array([0.62663155, 0.52225021, 0.5       , 0.5       , 0.62521945,\n",
      "       0.53992062, 0.5       , 0.5       , 0.62182276, 0.56278147,\n",
      "       0.5       , 0.5       , 0.62086864, 0.55392718, 0.5       ,\n",
      "       0.5       , 0.62086864, 0.55392718, 0.5       , 0.5       ,\n",
      "       0.62086864, 0.55392718, 0.5       , 0.5       ]), 'split4_test_score': array([0.57552859, 0.47160522, 0.5       , 0.5       , 0.57560492,\n",
      "       0.47732997, 0.5       , 0.5       , 0.57705519, 0.48545913,\n",
      "       0.5       , 0.5       , 0.58964965, 0.47549805, 0.5       ,\n",
      "       0.5       , 0.58964965, 0.47549805, 0.5       , 0.5       ,\n",
      "       0.58964965, 0.47549805, 0.5       , 0.5       ]), 'mean_test_score': array([0.60249645, 0.49259317, 0.5       , 0.5       , 0.60648771,\n",
      "       0.50630443, 0.5       , 0.5       , 0.6059349 , 0.51091189,\n",
      "       0.5       , 0.5       , 0.60714648, 0.50672323, 0.5       ,\n",
      "       0.5       , 0.60714648, 0.50672323, 0.5       , 0.5       ,\n",
      "       0.60714648, 0.50672323, 0.5       , 0.5       ]), 'std_test_score': array([0.03569612, 0.02077542, 0.        , 0.        , 0.03568675,\n",
      "       0.02673704, 0.        , 0.        , 0.03424563, 0.03772986,\n",
      "       0.        , 0.        , 0.03123268, 0.03781056, 0.        ,\n",
      "       0.        , 0.03123268, 0.03781056, 0.        , 0.        ,\n",
      "       0.03123268, 0.03781056, 0.        , 0.        ]), 'rank_test_score': array([ 6, 24, 12, 12,  4, 11, 12, 12,  5,  7, 12, 12,  1,  8, 12, 12,  1,\n",
      "        8, 12, 12,  1,  8, 12, 12])}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "# choisir 6 valeurs pour C, entre 1e-2 et 1e3\n",
    "C_range = np.logspace(-2, 3, 6)\n",
    "\n",
    "# choisir 4 valeurs pour gamma, entre 1e-2 et 10\n",
    "gamma_range = np.logspace(-2, 1, 4)\n",
    "\n",
    "# grille de paramètres\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range}\n",
    "\n",
    "# critère de sélection du meilleur modèle\n",
    "score = 'roc_auc'\n",
    "\n",
    "# initialiser une recherche sur grille\n",
    "grid = model_selection.GridSearchCV(svm.SVC(kernel='rbf'), \n",
    "                                    param_grid, \n",
    "                                    cv=cv, # 5 folds de validation croisée  \n",
    "                                    scoring=score)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# faire tourner la recherche sur grille\n",
    "grid.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed1 = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "# prédire sur le jeu de test avec le modèle optimisé\n",
    "y_test_pred_cv = grid.decision_function(X_test_std)\n",
    "\n",
    "y_proba_cv = (1/(1 + np.exp(-y_test_pred_cv)))\n",
    "\n",
    "\n",
    "roc_value = roc_auc_score(y_test, y_proba_cv)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed1))\n",
    "# afficher les paramètres optimaux\n",
    "print(\"The optimal parameters are {} with a score of {:.2f}\".format(grid.best_params_, grid.best_score_))\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.57 time 0.89s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "lr = LogisticRegression(solver = 'newton-cg', n_jobs=1)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr.fit(X_train_std,y_train)\n",
    "\n",
    "# On récupère la prédiction de la valeur positive\n",
    "y_prob = lr.predict_proba(X_test_std)[:,1]\n",
    "\n",
    "elapsed2 = timeit.default_timer() - start_time\n",
    "\n",
    "# On créé un vecteur de prédiction à partir du vecteur de probabilités\n",
    "y_pred = np.where(y_prob > 0.5, 1, 0)\n",
    "\n",
    "roc_value = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.50 time 894.78s\n",
      "Best Score: 0.6968742674836486\n",
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model = LogisticRegression()\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['liblinear']\n",
    "space['penalty'] = ['l1', 'l2']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='roc_auc', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "result = search.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed3 = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "\n",
    "# On récupère la prédiction de la valeur positive\n",
    "y_prob_cv = result.predict_proba(X_test_std)[:,1] \n",
    "\n",
    "# On créé un vecteur de prédiction à partir du vecteur de probabilités\n",
    "y_pred_cv = np.where(http://localhost:8889/notebooks/P7_GIT_GUI/P7_tous_les_mod%C3%A8les.ipynb#RandomForestClassifiery_prob_cv > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "roc_value = roc_auc_score(y_test, y_pred_cv)\n",
    "\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed3))\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "#print(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.61 time 2.61s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rfc = RandomForestClassifier(oob_score=True, random_state = 42)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "model = rfc.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed4 = timeit.default_timer() - start_time\n",
    "\n",
    "# Actual class predictions\n",
    "rf_predictions = model.predict(X_test_std)\n",
    "\n",
    "# Probabilities for each class\n",
    "rf_probs = model.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.61 time 121.35s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \n",
    "    'max_depth': [60, 70, 80],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2,3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                                 cv = cv, n_jobs = -1,scoring='roc_auc', return_train_score=False)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "grid_search.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed5 = timeit.default_timer() - start_time\n",
    "\n",
    "predictions = grid_search.predict(X_test_std)\n",
    "    \n",
    "# Probabilities for each class\n",
    "rf_probs = model.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, rf_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.666890256406924\n",
      "Best Hyperparameters: {'max_depth': 60, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % grid_search.best_score_)\n",
    "print('Best Hyperparameters: %s' % grid_search.best_params_)\n",
    "#print(result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.69 time 15.92s\n"
     ]
    }
   ],
   "source": [
    "# import machine learning algorithms\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "gb = GradientBoostingClassifier(random_state = 42)\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "gb.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed7 = timeit.default_timer() - start_time\n",
    "\n",
    "predictions = gb.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, predictions)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.67 time 1914.10s\n",
      "Best Score: 0.6938194206077556\n",
      "Best Hyperparameters: {'max_depth': 80, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 500, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 400, 700],\n",
    "    \n",
    "    'max_depth': [60, 70, 80],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2,3],\n",
    "    'min_samples_split': [100, 300, 500],\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_gbc = GridSearchCV(estimator = gbc, param_grid = param_grid, \n",
    "                                 cv = cv, n_jobs = -1, scoring='roc_auc', return_train_score=False)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "grid_search_gbc.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed9 = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "predictions = grid_search_gbc.predict(X_test_std)\n",
    "    \n",
    "# Probabilities for each class\n",
    "gbc_probs = grid_search_gbc.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, gbc_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed9))\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % grid_search_gbc.best_score_)\n",
    "print('Best Hyperparameters: %s' % grid_search_gbc.best_params_)\n",
    "#print(grid_search_gbc.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.71 time 4.25s\n"
     ]
    }
   ],
   "source": [
    "lg = LGBMClassifier(random_state = 42)\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "lg.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed10 = timeit.default_timer() - start_time\n",
    "\n",
    "predictions = lg.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, predictions)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.70 time 2707.60s\n",
      "Best Score: 0.7088586676337998\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'num_leaves': 8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    " \n",
    "parameters = {\n",
    "              'n_estimators' : [100, 400, 700],\n",
    "              'max_depth': [15, 25, 35],\n",
    "              'learning_rate': [0.01,  0.05, 0.15],\n",
    "              'num_leaves': [8, 15, 25]\n",
    "              \n",
    "}\n",
    "lgbm = LGBMClassifier()\n",
    " # With gridsearch we don't need the fit function\n",
    "gsearch_lgbm = GridSearchCV(lgbm, param_grid=parameters, cv=cv, n_jobs = -1, scoring='roc_auc')\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "gsearch_lgbm.fit(X_train_std, y_train)\n",
    "\n",
    "elapsed11 = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "predictions = gsearch_lgbm.predict(X_test_std)\n",
    "    \n",
    "# Probabilities for each class\n",
    "lgbm_probs = gsearch_lgbm.predict_proba(X_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y_test, lgbm_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed11))\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % gsearch_lgbm.best_score_)\n",
    "print('Best Hyperparameters: %s' % gsearch_lgbm.best_params_)\n",
    "#print(gsearch_lgbm.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic ={'Temps_normal' : ['8.07s', '0.89s', '2.61s', '15.92s', '4.25s'],\n",
    "      'Roc_nrmal' : [0.69, 0.57, 0.61, 0.69, 0.71],\n",
    "      'Temps_grid' : ['635.99s', '894.78s', '121.35s', '1914.10s', '2707.60s'],\n",
    "      'Roc_grid' : [0.71, 0.50, 0.61, 0.67, 0.70]\n",
    "    \n",
    "}\n",
    "\n",
    "lst = ['svm.', 'L_Regression', 'RandomForest', 'GradientBoosting', 'LGBM' ]\n",
    "\n",
    "test_models = pd.DataFrame((dic), index=lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temps_normal</th>\n",
       "      <th>Roc_nrmal</th>\n",
       "      <th>Temps_grid</th>\n",
       "      <th>Roc_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>svm.</td>\n",
       "      <td>8.07s</td>\n",
       "      <td>0.69</td>\n",
       "      <td>635.99s</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>L_Regression</td>\n",
       "      <td>0.89s</td>\n",
       "      <td>0.57</td>\n",
       "      <td>894.78s</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForest</td>\n",
       "      <td>2.61s</td>\n",
       "      <td>0.61</td>\n",
       "      <td>121.35s</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>15.92s</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1914.10s</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LGBM</td>\n",
       "      <td>4.25s</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2707.60s</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Temps_normal  Roc_nrmal Temps_grid  Roc_grid\n",
       "svm.                    8.07s       0.69    635.99s      0.71\n",
       "L_Regression            0.89s       0.57    894.78s      0.50\n",
       "RandomForest            2.61s       0.61    121.35s      0.61\n",
       "GradientBoosting       15.92s       0.69   1914.10s      0.67\n",
       "LGBM                    4.25s       0.71   2707.60s      0.70"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deuxième test sur 10% des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = df2.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1= dataset1.drop(['TARGET','SK_ID_CURR','index'], axis=1).values\n",
    "y1 = dataset1['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X1_train, X1_test, y1_train, y1_test = \\\n",
    "    model_selection.train_test_split(X1, y1, test_size=0.3, stratify=y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X1_train)\n",
    "\n",
    "X1_train_std = std_scale.transform(X1_train)\n",
    "X1_test_std = std_scale.transform(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.50 time 0.00s\n"
     ]
    }
   ],
   "source": [
    "dclf = DummyClassifier(strategy = 'most_frequent', random_state =42) \n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "dclf.fit(X1_train_std, y1_train)\n",
    "\n",
    "elapsed0 = timeit.default_timer() - start_time\n",
    "\n",
    "y_pred_dum = dclf.predict(X1_test_std)\n",
    "\n",
    "y_prob_dum = dclf.predict_proba(X1_test_std)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y1_test, y_prob_dum)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.68 time 2155.60s\n"
     ]
    }
   ],
   "source": [
    "# Créer une SVM avec un noyau gaussien de paramètre gamma=0.01\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='rbf', gamma=0.01, random_state =42)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Entraîner la SVM sur le jeu d'entraînement\n",
    "classifier.fit(X1_train_std, y1_train)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "# prédire sur le jeu de test\n",
    "y_test_pred = classifier.decision_function(X1_test_std)\n",
    "\n",
    "y_proba = (1/(1 + np.exp(-y_test_pred)))\n",
    "\n",
    "\n",
    "\n",
    "roc_value = roc_auc_score(y1_test, y_proba)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.69 time 57.24s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rfc = RandomForestClassifier(oob_score=True, random_state = 42)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "model = rfc.fit(X1_train_std, y1_train)\n",
    "\n",
    "elapsed4 = timeit.default_timer() - start_time\n",
    "\n",
    "# Actual class predictions\n",
    "rf_predictions = model.predict(X1_test_std)\n",
    "\n",
    "# Probabilities for each class\n",
    "rf_probs = model.predict_proba(X1_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y1_test, rf_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.69 time 2479.78s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \n",
    "    'max_depth': [60, 70, 80],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2,3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                                 cv = cv, n_jobs = -1,scoring='roc_auc', return_train_score=False)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "grid_search.fit(X1_train_std, y1_train)\n",
    "\n",
    "elapsed5 = timeit.default_timer() - start_time\n",
    "\n",
    "predictions = grid_search.predict(X1_test_std)\n",
    "    \n",
    "# Probabilities for each class\n",
    "rf_probs = model.predict_proba(X1_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y1_test, rf_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.75 time 18.05s\n"
     ]
    }
   ],
   "source": [
    "lg = LGBMClassifier(random_state = 42)\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "lg.fit(X1_train_std, y1_train)\n",
    "\n",
    "elapsed10 = timeit.default_timer() - start_time\n",
    "\n",
    "predictions = lg.predict_proba(X1_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y1_test, predictions)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.77 time 7661.16s\n",
      "Best Score: 0.7580049193052539\n",
      "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 700, 'num_leaves': 25}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    " \n",
    "parameters = {\n",
    "              'n_estimators' : [100, 400, 700],\n",
    "              'max_depth': [15, 25, 35],\n",
    "              'learning_rate': [0.01,  0.05, 0.15],\n",
    "              'num_leaves': [8, 15, 25]\n",
    "              \n",
    "}\n",
    "lgbm = LGBMClassifier()\n",
    " # With gridsearch we don't need the fit function\n",
    "gsearch_lgbm = GridSearchCV(lgbm, param_grid=parameters, cv=cv, n_jobs = -1, scoring='roc_auc')\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "gsearch_lgbm.fit(X1_train_std, y1_train)\n",
    "\n",
    "elapsed11 = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "predictions = gsearch_lgbm.predict(X1_test_std)\n",
    "    \n",
    "# Probabilities for each class\n",
    "lgbm_probs = gsearch_lgbm.predict_proba(X1_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y1_test, lgbm_probs)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed11))\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % gsearch_lgbm.best_score_)\n",
    "print('Best Hyperparameters: %s' % gsearch_lgbm.best_params_)\n",
    "#print(gsearch_lgbm.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troisième test sur 100% des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307507, 798)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2= df2.drop(['TARGET','SK_ID_CURR','index'], axis=1).values\n",
    "y2 = df2['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X2_train, X2_test, y2_train, y2_test = \\\n",
    "    model_selection.train_test_split(X2, y2, test_size=0.3, stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X2_train)\n",
    "\n",
    "X2_train_std = std_scale.transform(X2_train)\n",
    "X2_test_std = std_scale.transform(X2_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.50 time 0.06s\n"
     ]
    }
   ],
   "source": [
    "dclf = DummyClassifier(strategy = 'most_frequent', random_state =42) \n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "dclf.fit(X2_train_std, y2_train)\n",
    "\n",
    "elapsed0 = timeit.default_timer() - start_time\n",
    "\n",
    "y_pred_dum = dclf.predict(X2_test_std)\n",
    "\n",
    "y_prob_dum = dclf.predict_proba(X2_test_std)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y2_test, y_prob_dum)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_cv 0.78 time 126.35s\n"
     ]
    }
   ],
   "source": [
    "lg = LGBMClassifier(random_state = 42)\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "lg.fit(X2_train_std, y2_train)\n",
    "\n",
    "elapsed12 = timeit.default_timer() - start_time\n",
    "\n",
    "predictions = lg.predict_proba(X2_test_std)[:, 1]\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(y2_test, predictions)\n",
    "\n",
    "print(\"auc_cv {:.2f} time {:.2f}s\".format(roc_value, elapsed12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': 42,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(r'D:\\Documents\\P7\\df2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voir le notebook qui contient le modèle final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
